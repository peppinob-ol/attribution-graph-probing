# Supernode-Level Robustness Analysis

**Method**: Concept Transfer & Entity Separation  
**Level**: Conceptual groupings (coarse-grained)  
**Complementary to**: Feature-Level Robustness (see `../feature_level_robustness/`)

---

## üéØ What This Method Tests

**Question**: Do conceptual groupings (supernodes) transfer appropriately when entities change?

**Why It Matters**: If supernodes represent genuine concepts (not spurious groupings), they should:
- **Universal concepts** (copula, prepositions) ‚Üí Transfer to both probes
- **Entity concepts** (state/city names) ‚Üí Appear in only one probe
- **Output concepts** ‚Üí Shift appropriately (Austin vs Sacramento)

This tests **semantic disentanglement**: Can the algorithm separate task structure from entity content?

---

## üìä Method Details

### Input
- Dallas probe: 195 features in supernodes
- Oakland probe: 230 features in supernodes
- Shared features: 25 appear in both

### Classification
Supernodes categorized as:

1. **Universal** (should transfer)
   - Task-invariant: copula, prepositions, operators
   - Examples: "is", "of", "capital", "(capital) related"

2. **Entity-Specific** (should NOT transfer)
   - Probe-specific: state/city names
   - Examples: "Texas", "Dallas" (Dallas probe only)

3. **Output** (should shift appropriately)
   - Answer promotion: "Say (Austin)" ‚Üí "Say (Sacramento)"

### Measurements

1. **Supernode Transfer Rate**
   - Universal: % present in both probes
   - Entity: % present in only one probe

2. **Activation Stability** (for shared features)
   - Mean relative difference in activation magnitudes
   - Peak token/type consistency

3. **Grouping Consistency**
   - Do shared features get equivalent supernode assignments?
   - Accounting for appropriate entity-dependence

### Output
- Transfer rates by category
- Activation stability metrics
- Grouping consistency (naive & corrected)

---

## ‚úÖ Results

| Metric | Value | Expected | Status |
|--------|-------|----------|--------|
| Universal Transfer | 100% (7/7) | ~100% | ‚úÖ PERFECT |
| Entity Separation | 100% (8/8) | ~100% | ‚úÖ PERFECT |
| Feature Overlap | 12.8% (25/195) | Low | ‚úÖ EXPECTED |
| Activation Stability | 94% | >80% | ‚úÖ HIGH |
| Grouping (naive) | 68% | >60% | ‚úÖ MODERATE |
| Grouping (corrected) | 96% | >80% | ‚úÖ HIGH |

---

## üìù Files in This Directory

- **`PAPER_READY_SUMMARY_CORRECTED.md`** ‚≠ê - Publication text (USE THIS FOR PAPER)
- **`VERIFIED_CLAIMS.md`** - All claims verified against raw data
- **`DOUBLE_CHECK_RESULTS.md`** - What changed after double-checking
- **`README.md`** - Detailed guide
- `supernode_transfer_20251027_183408.csv` - Which supernodes appear where
- `activation_similarity_20251027_183408.csv` - Shared feature metrics
- `cross_prompt_report_20251027_183408.md` - Technical report
- `cross_prompt_robustness_20251027_183408.png` - 5-panel visualization
- `figure_supernode_transfer_matrix.png` - Transfer matrix

---

## üéØ For Paper Writing

### Supernode-Level Paragraph (Results Section)

> "At the supernode level, we verified whether conceptual groupings transfer appropriately across entity swaps. Universal concept supernodes demonstrated perfect transfer (7/7 including copula, prepositions, relational operators), while entity-specific supernodes showed perfect appropriate non-transfer (8/8 including state and city names). Among 25 shared features (12.8% of Dallas probe), 94% exhibited stable activation profiles (mean relative difference 0.058), with 68% grouped into equivalent universal supernodes and 28% showing appropriate entity-dependent variation. This demonstrates semantic disentanglement: universal concepts generalize, entity concepts don't (as they should)."

### Citation
When citing this method: "supernode-level concept transfer analysis"

---

## üî¨ Complementary Method

This analysis focuses on **semantic organization** of conceptual groupings.

For **computational stability** of individual features, see:
- `../feature_level_robustness/` - Tests whether features maintain activation patterns

**Together**, these provide dual-level validation:
- ‚úÖ Features are stable (feature method)
- ‚úÖ Concepts are organized (this method)

---

## üîÑ Reproducibility

```bash
cd scripts/experiments
python run_cross_prompt_analysis.py
```

Or with custom probes:
```bash
python analyze_cross_prompt_robustness.py \
    --probe1-csv "output/examples/Dallas/node_grouping_final_20251027_173744.csv" \
    --probe1-json "output/examples/Dallas/node_grouping_summary_20251027_173749.json" \
    --probe1-name "Dallas" \
    --probe2-csv "output/examples/capital oakland/node_grouping_final_20251027_180941.csv" \
    --probe2-json "output/examples/capital oakland/node_grouping_summary_20251027_180951.json" \
    --probe2-name "Oakland" \
    --output-dir "output/validation/supernode_level_robustness"
```

Verify all claims:
```bash
cd scripts/experiments
python verify_claims.py
```

---

## ‚ö†Ô∏è Important: 68% vs 96% Grouping Consistency

**Naive count**: 68% (17/25 features)
- Simply compares supernode names
- Doesn't account for appropriate entity-dependence

**Corrected count**: 96% (24/25 features)
- 68% universal features consistently grouped
- 28% entity features appropriately different (correct!)
- 4% genuinely inconsistent (1 feature)

**Always use the corrected interpretation in the paper.**

See `DOUBLE_CHECK_RESULTS.md` for full explanation.

---

## üìä Comparison with Feature Method

| Aspect | Supernode-Level (This) | Feature-Level (Other) |
|--------|----------------------|----------------------|
| **Granularity** | Coarse (7-8 supernodes) | Fine (25 features) |
| **Tests** | Concept transfer | Activation stability |
| **Metric** | Transfer/separation rate | Overlap, survival |
| **Validates** | Semantic disentanglement | Computational robustness |
| **Best for** | "Concepts organize correctly" | "Features are stable" |

---

## üéì Key Insight: Low Overlap is GOOD

**12.8% feature overlap** might look concerning, but it's actually evidence of:
- High entity-specificity (most features encode specific facts)
- Good disentanglement (features aren't generic/reused everywhere)
- Expected behavior (Austin vs Sacramento need different features)

**High overlap would be suspicious** - it would suggest the model uses generic features for everything.

---

## ‚úÖ Key Takeaways

**Claim**: Supernodes represent semantically disentangled concepts.

**Evidence**: 
- 100% universal transfer (concepts generalize)
- 100% entity separation (no concept bleeding)
- 96% correct grouping (accounting for entity-dependence)

**Strength**: Perfect discrimination at supernode level.

**For complete validation**, combine with feature-level analysis.

---

## üìö What Changed After Double-Checking

After the user requested cautious verification:
1. ‚úÖ Confirmed all 100% metrics against raw data
2. ‚ö†Ô∏è Discovered 68% grouping consistency needs context
3. ‚úÖ Corrected interpretation: 96% when accounting for entity features
4. üêõ Fixed bug in automated summary statistics
5. ‚úÖ All numbers now traceable to CSV files

See `DOUBLE_CHECK_RESULTS.md` for full audit trail.

---

## üìÑ Files to Use for Paper

**Primary**: `PAPER_READY_SUMMARY_CORRECTED.md`
- Results section text (ready to copy)
- Discussion section text
- Limitations section
- Table 3 (formatted)
- Figure caption

**Verification**: `VERIFIED_CLAIMS.md`
- Confidence ratings for each claim
- What to claim vs avoid
- Safe vs risky statements

**Understanding**: `DOUBLE_CHECK_RESULTS.md`
- What changed and why
- Explanation of corrections

---

**Method**: Supernode-Level Concept Transfer  
**Status**: ‚úÖ Complete, Double-Checked, Publication-Ready  
**See also**: `../CROSS_PROMPT_ROBUSTNESS_MASTER.md` for combined overview

